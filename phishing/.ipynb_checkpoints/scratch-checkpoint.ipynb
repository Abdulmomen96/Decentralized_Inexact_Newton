{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "416a3891",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dataframe = pd.read_csv(\"Phishing_Legitimate_full.csv\")\n",
    "\n",
    "dataframe.head()\n",
    "\n",
    "X = dataframe[dataframe.columns.difference([\"CLASS_LABEL\"])].to_numpy()\n",
    "y = dataframe[\"CLASS_LABEL\"].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "167af057",
   "metadata": {},
   "outputs": [],
   "source": [
    "y =y * 1.\n",
    "y[y < 0.5] = -1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0fc8858",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1977\n",
      "100\n",
      "Best rho:  0.0001   Op gap: : 0.015185833114297498\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# In[1]:\n",
    "\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "import scipy\n",
    "import networkx as nx\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import log_loss\n",
    "from numpy import linalg as LA\n",
    "\n",
    "\n",
    "# In[2]:\n",
    "\n",
    "\n",
    "seed = 42\n",
    "no_users = 100\n",
    "lambda_logistic = 1e-3\n",
    "\n",
    "\n",
    "# In[3]:\n",
    "\n",
    "\n",
    "def random_split(X, y, n, seed):\n",
    "    \"\"\"Equally split data between n agents\"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "    perm = rng.permutation(y.size)\n",
    "    X_split = np.array_split(X[perm], n)  #np.stack to keep as a np array\n",
    "    y_split = np.array_split(y[perm], n)\n",
    "    return X_split, y_split\n",
    "\n",
    "\n",
    "# In[4]:\n",
    "\n",
    "\n",
    "def loss(w, A, b, l2):\n",
    "    z = b * np.dot(A, w)\n",
    "    tmp = np.minimum(z, 0)\n",
    "    loss = np.log((np.exp(tmp) + np.exp(tmp - z)) / np.exp(tmp))\n",
    "    loss_sum = np.sum(loss) / len(b)\n",
    "    reg = (np.linalg.norm(w) ** 2) * l2 / 2\n",
    "    return loss_sum + reg\n",
    "\n",
    "\n",
    "# In[5]:\n",
    "\n",
    "\n",
    "def gradient(w, A, b, l2):\n",
    "    m = A.shape[0]\n",
    "    z = b * np.dot(A, w)\n",
    "    tmp0 = np.minimum(z, 0)\n",
    "    tmp1 = np.exp(tmp0 - z) / ((np.exp(tmp0) + np.exp(tmp0 - z)))\n",
    "    tmp2 = - tmp1 * b\n",
    "    res = np.dot(A.T, tmp2) / m + l2 * w\n",
    "    return res\n",
    "\n",
    "\n",
    "# In[6]:\n",
    "\n",
    "\n",
    "def hessian(w, A, b, l2):\n",
    "    Aw = A @ w\n",
    "    activation = scipy.special.expit(Aw)\n",
    "    weights = activation * (1-activation)\n",
    "    A_weighted = np.multiply(A.T, weights)\n",
    "    return A_weighted@A/A.shape[0] + l2*np.eye(A.shape[1])\n",
    "\n",
    "\n",
    "# In[7]:\n",
    "\n",
    "\n",
    "def degrees(A):\n",
    "    \"\"\"Return the degrees of each node of a graph from its adjacency matrix\"\"\"\n",
    "    return np.sum(A, axis=0).reshape(A.shape[0], 1)\n",
    "\n",
    "\n",
    "# In[8]:\n",
    "\n",
    "\n",
    "def generate_graph(n, seed):\n",
    "    \"\"\"Generate a random connected graph\"\"\"\n",
    "    while True:\n",
    "        g = nx.generators.random_graphs.binomial_graph(n, 0.4, seed = seed) \n",
    "        # g = nx.random_geometric_graph(n, 0.4, seed = seed)\n",
    "        #g = nx.grid_2d_graph(int(n/5), int(n/5))\n",
    "        if nx.algorithms.components.is_connected(g):\n",
    "            return g\n",
    "\n",
    "\n",
    "# In[9]:\n",
    "\n",
    "\n",
    "G = generate_graph(no_users, seed)\n",
    "adjacency_matrix = nx.linalg.graphmatrix.adjacency_matrix(G)\n",
    "print(G.number_of_edges())\n",
    "print(G.number_of_nodes())\n",
    "#nx.draw(G, with_labels=True, font_weight='bold')\n",
    "\n",
    "\n",
    "# In[10]:\n",
    "\n",
    "\n",
    "#X = np.load('X.npy')\n",
    "#y = np.load('y.npy').ravel()\n",
    "#y[y < 0.5] = -1.\n",
    "num_feature = X.shape[1] #+ 1 #+1 for bias\n",
    "\n",
    "\n",
    "# In[11]:\n",
    "\n",
    "\n",
    "X, y = random_split(X, y, no_users, seed)\n",
    "\n",
    "rhos = list(np.linspace(0.0001, 0.001, num=40, endpoint=True, retstep=False, dtype=None, axis=0))\n",
    "\n",
    "min_opgap = 10\n",
    "\n",
    "best_rho = 10\n",
    "\n",
    "for rho in rhos:\n",
    "\n",
    "    theta = [np.zeros(num_feature) for _ in range(no_users)] # initial model\n",
    "\n",
    "    d_new = [np.zeros(num_feature) for _ in range(no_users)] # direction\n",
    "    d_old = [np.zeros(num_feature) for _ in range(no_users)] # old direction\n",
    "\n",
    "    lamd = [np.zeros(num_feature) for _ in range(no_users)] # dual variables\n",
    "\n",
    "    grad = [np.zeros(num_feature) for _ in range(no_users)] # old grads\n",
    "    Hess = [np.zeros([num_feature, num_feature]) for _ in range(no_users)] # old hessians\n",
    "\n",
    "\n",
    "    # In[12]:\n",
    "\n",
    "\n",
    "    # Optimal objective function, i.e., f(x*)\n",
    "    obj0 = 0.33458104150211826 # a1a dataset\n",
    "\n",
    "    #n_iters = 200\n",
    "    # rho0 = 0.01, per = 1, factor = 0.5 \n",
    "    #rho0 = 0.1\n",
    "    #per = 1\n",
    "    #factor = 0.85\n",
    "    #alpha = 0.025\n",
    "    #rho =[rho0*factor**(np.floor(t/per)) for t in range(n_iters)]\n",
    "    # In[13]:\n",
    "\n",
    "\n",
    "    n_iters = 200\n",
    "    rho =[rho for t in range(n_iters)]\n",
    "    alpha = 10 * rho[0]\n",
    "    # Best: rho=0.003, alpha = 0.045\n",
    "    # Best: rho=0.001, alpha = 0.025\n",
    "\n",
    "\n",
    "    # In[14]:\n",
    "\n",
    "\n",
    "    losses_dnl = []\n",
    "    accuracies_dnl = []\n",
    "    op_gap_dnl = np.zeros(shape=[n_iters])\n",
    "\n",
    "    for k in range(n_iters):\n",
    "        #print(k)\n",
    "        for i in range(no_users):        \n",
    "            grad[i] = gradient(theta[i], X[i], y[i], lambda_logistic)\n",
    "            Hess[i] = hessian(theta[i], X[i], y[i], lambda_logistic)\n",
    "\n",
    "        for i in range(no_users):\n",
    "            w_neighbors_sum = np.zeros(num_feature)\n",
    "            for j in G.neighbors(i):\n",
    "                w_neighbors_sum = np.add(w_neighbors_sum, d_old[j])\n",
    "            degree = G.degree(i)\n",
    "            d_new[i] = np.matmul(np.linalg.inv(Hess[i] + (2 * degree * rho[k] + alpha) * np.eye(num_feature)),                                        grad[i] - lamd[i] + rho[k] * (degree * d_old[i] + w_neighbors_sum))\n",
    "\n",
    "\n",
    "\n",
    "        # Dual Variable Update\n",
    "        for i in range(no_users):\n",
    "            w_neighbors_sum = np.zeros(num_feature)\n",
    "            for j in G.neighbors(i):\n",
    "                w_neighbors_sum = np.add(w_neighbors_sum, d_new[j])\n",
    "            degree = G.degree(i)\n",
    "            lamd[i] = lamd[i] + rho[k] * (degree * d_new[i] - w_neighbors_sum)\n",
    "       # print('dual: ', LA.norm(lamd[0]))\n",
    "\n",
    "\n",
    "        for i in range(no_users):\n",
    "            theta[i] = theta[i] - d_new[i]\n",
    "            d_old[i] = d_new[i]\n",
    "\n",
    "       # Performance Check\n",
    "\n",
    "        theta_avg = 1/no_users*sum(theta)\n",
    "\n",
    "        for i in range(no_users):\n",
    "            loss_dnl = np.mean([loss(theta_avg, X[i], y[i], lambda_logistic) for i in range(no_users)])\n",
    "            losses_dnl.append(loss_dnl)\n",
    "\n",
    "        op_gap_dnl[k] = np.abs(losses_dnl[-1] - obj0)\n",
    "    \n",
    "    if op_gap_dnl[-1] < min_opgap:\n",
    "        min_opgap = op_gap_dnl[-1]\n",
    "        best_rho = rho\n",
    "        print(\"Best rho: \", rho[0], \"  Op gap: :\", min_opgap)\n",
    "\n",
    "\n",
    "# # Optimality Gap\n",
    "\n",
    "# In[15]:\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.semilogy(op_gap_dnl)\n",
    "#plt.ylim([10**(-5),0.5])\n",
    "np.save('op_gap_dnl', op_gap_dnl)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed8c278",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
